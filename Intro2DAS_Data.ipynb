{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "949c1382",
   "metadata": {},
   "source": [
    "<img src=\"M_earth.png\"\n",
    "     width=\"120\" height=\"120\"\n",
    "     style=\"float: right; margin-right: 5px;\" />\n",
    "     \n",
    "# Intro to Distributed Acoustic Sensing (DAS) data\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## Introduction\n",
    "In this notebook, we will introduce some DAS data analysis using two dataset in HDF5 format. The first part is to read one DAS earthquake data from Mexico and conduct some basic processing to understand DAS data. The second part gives one example of ocean bottom DAS and visulizes it in frequency-wavenumber (f-k) domain.\n",
    "\n",
    "**Contents:**\n",
    "- DAS earthquake data from Mexico City\n",
    "- Ocean bottom DAS data in f-k plot\n",
    "\n",
    "**Objectives:** \n",
    "- Get started with DAS \n",
    "- Read and visualize DAS data\n",
    "- Analyze data in frequency domain \n",
    "\n",
    "---\n",
    "\n",
    "## Part 1. DAS earthquake data from Mexico City"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9b9aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import string\n",
    "import glob\n",
    "import os, psutil\n",
    "import time\n",
    "\n",
    "from scipy import signal\n",
    "import scipy.fftpack as fft\n",
    "from scipy.fftpack import fft2,ifft2, fftshift,ifftshift, fftfreq\n",
    "\n",
    "import obspy\n",
    "from obspy import UTCDateTime as UTC\n",
    "from obspy.signal.filter import bandpass\n",
    "from obspy.signal.tf_misfit import plot_tfr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "546acdf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pylab as pylab\n",
    "params = {'legend.fontsize': 'large',\n",
    "         'axes.labelsize': 'large',\n",
    "         'xtick.labelsize':'large',\n",
    "         'ytick.labelsize':'large',\n",
    "         'axes.titlesize': 'x-large',\n",
    "         'image.cmap': 'RdBu'\n",
    "         }\n",
    "pylab.rcParams.update(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56a546a0",
   "metadata": {},
   "source": [
    "### Reading DAS data using h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "648102c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the DAS data and check keys in it\n",
    "h5 = h5py.File('Mw_4.7_raw.h5', 'r')\n",
    "h5.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2e5532",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print data information\n",
    "chan = h5['Channels'][()]\n",
    "t = h5['t'][()]\n",
    "DAS = h5['DAS'][()] \n",
    "\n",
    "fs = 1/(t[1]-t[0]) # sampling rate\n",
    "print('Channels start from {:3d} to {:3d}.'.format(chan[0], chan[-1]))\n",
    "print('The duration of the time series is {:.1f} s with a sampling rate of {:.1f} Hz.'\n",
    "        .format(t[-1], fs))\n",
    "print('This DAS data has a shape of', np.shape(DAS))\n",
    "h5.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd57e55",
   "metadata": {},
   "source": [
    "### Visualizing DAS data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef92132",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot data recorded by one single channel\n",
    "# Example: Chan #1000\n",
    "chan_id = 2000\n",
    "das_tr = DAS[chan_id-100]\n",
    "fig, ax = plt.subplots(figsize=(10, 4))\n",
    "ax.plot(t, das_tr, color='black', label='Chan #'+str(chan_id))\n",
    "ax.set_xlabel('Time (s)')\n",
    "ax.set_ylabel('Amplitude')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e829ae75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot 2-D DAS data using imshow\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "im = ax.imshow(DAS, aspect='auto', extent=[min(t),max(t), min(chan), max(chan)])\n",
    "ax.set_xlabel('Time (s)')\n",
    "ax.set_ylabel('Channel')\n",
    "plt.colorbar(im, ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b7beb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determining Upper and Lower Limits of the Data\n",
    "vm = np.percentile(DAS, 90)\n",
    "std = np.std(DAS)\n",
    "print(\"The max and min amplitude is {:.4f}, {:.4f}\"\n",
    ".format(DAS.min(), DAS.max()))\n",
    "print(\"The 90th percentile is {:.4f}; the standard deviation is {:.4f}.\"\n",
    ".format(vm, std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65bd338",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use vmin and vmax to define the data range that the colormap covers\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "im = ax.imshow(DAS, aspect='auto', vmin=-vm-std, vmax=vm+std, extent=[min(t),max(t), min(chan), max(chan)])\n",
    "ax.set_xlabel('Time (s)')\n",
    "ax.set_ylabel('Channel')\n",
    "plt.colorbar(im, ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baefef73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# It's more obvious to use narrow data range \n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "im = ax.imshow(DAS, aspect='auto', vmin=-30, vmax=30, extent=[min(t),max(t), min(chan), max(chan)])\n",
    "ax.set_xlabel('Time (s)')\n",
    "ax.set_ylabel('Channel')\n",
    "plt.colorbar(im, ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "882d9e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhance the signal by averaging nearby channels\n",
    "\n",
    "def das_ave_2Nadd1(DAS, N):\n",
    "    \"\"\"\n",
    "    Enhance the signal through averaging data from surrounding channels [-N, N]\n",
    "    The mean trace will be obtained by 2N+1 total traces\n",
    "    Parameters:\n",
    "    ------------\n",
    "    DAS: - DAS data with shape of [c, t], \n",
    "         - c is the number of channels and t is the number of sampling points.\n",
    "    N  : Number of channels before and after one trace.\n",
    "    \"\"\"\n",
    "\n",
    "    DAS = np.concatenate((DAS[:N], DAS, DAS[-N:]))\n",
    "    das_ave = [] #np.zeros(DAS.shape, DAS.dtype)\n",
    "    for chan in range(N, DAS.shape[0]-N):\n",
    "        if chan==N:\n",
    "            sum_tr = np.sum(DAS[:2*N+1],axis=0)\n",
    "        else:\n",
    "            sum_tr = sum_tr - DAS[chan-N-1] + DAS[chan+N]\n",
    "\n",
    "        das_ave.append(sum_tr)\n",
    "    das_ave = np.array(das_ave)/(2*N+1)\n",
    "    \n",
    "    return das_ave\n",
    "\n",
    "def plot_2_das(das1, das2, t, chan, title1='Raw data', title2='Data 2'):\n",
    "    \"\"\"\n",
    "    Plot two DAS data \n",
    "    \"\"\"\n",
    "    from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "    \n",
    "    fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(15, 6), sharey=True, )\n",
    "    im0 = ax[0].imshow(das1, aspect='auto', vmin=-30, vmax=30, \n",
    "                extent=[min(t),max(t), min(chan), max(chan)])\n",
    "    im1 = ax[1].imshow(das2, aspect='auto', vmin=-30, vmax=30, \n",
    "                extent=[min(t),max(t), min(chan), max(chan)])\n",
    "    ax[0].set_xlabel('Time (s)')\n",
    "    ax[1].set_xlabel('Time (s)')\n",
    "    ax[0].set_ylabel('Channel')\n",
    "    ax[0].set_title(title1)\n",
    "    ax[1].set_title(title2)\n",
    "\n",
    "    divider = make_axes_locatable(plt.gca())\n",
    "    cax = divider.append_axes(\"right\", \"4%\", pad=\"3%\")\n",
    "    fig.colorbar(im1, cax=cax)\n",
    "    fig.tight_layout()\n",
    "    plt.show()     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f7059e",
   "metadata": {},
   "outputs": [],
   "source": [
    "das_ave = das_ave_2Nadd1(DAS, N=15)\n",
    "plot_2_das(DAS, das_ave, t, chan, title2='Average of surrounding channels')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff003a3a",
   "metadata": {},
   "source": [
    "### Spectral analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb203d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "chan_id = 1000\n",
    "das_tr = DAS[chan_id-100]\n",
    "\n",
    "tr_fft = fft.fft(das_tr)\n",
    "f_len = int(tr_fft.size/2)\n",
    "NqF = fs/2.0  #the Nyquist frequency\n",
    "frequency = np.linspace(0, NqF, num=f_len)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 4))\n",
    "ax.semilogx(frequency, abs(tr_fft[:f_len]), color='black', \n",
    "            label='FFT of Chan #'+str(chan_id))\n",
    "ax.set_xlabel('Frequency (Hz)')\n",
    "ax.set_ylabel('Amplitude')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c980c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot time frequency representation, spectrum and time series of the signal.\n",
    "fmin = 0.1\n",
    "fmax = 50\n",
    "plt.figure(figsize=(10, 8))\n",
    "plot_tfr(das_tr, dt=1/fs, fmin=fmin, fmax=fmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f29593a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform basic processing  \n",
    "# demean, detrend, filtering\n",
    "das_pro = DAS - DAS.mean(axis=1, keepdims=True)\n",
    "das_pro = signal.detrend(das_pro,type='constant')\n",
    "das_pro = signal.detrend(das_pro,type='linear')\n",
    "\n",
    "fmin1 = 0.2; fmax1 = 2;\n",
    "das_filt1 = np.float32(bandpass(das_pro, fmin1, fmax1, \n",
    "                                df=fs, corners=4, zerophase=True))\n",
    "plot_2_das(das_pro, das_filt1, t, chan, \n",
    "            title1='After removing mean and trend', \n",
    "            title2='Filtering data '+str(fmin1)+'-'+str(fmax1)+' Hz')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "929470de",
   "metadata": {},
   "source": [
    "### Resampling data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e26c7c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# downsampling data from 200 to 50 Hz\n",
    "new_sampling_rate = 50 \n",
    "decimate_s = int(fs/new_sampling_rate)\n",
    "das_dws = signal.decimate(das_pro, decimate_s, ftype='iir', zero_phase=True)\n",
    "print('The shape of downsampling data is', das_dws.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111f4e70",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_2_das(das_pro, das_dws, t, chan, \n",
    "            title1='After removing mean and trend',          \n",
    "            title2='Downsampling data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e0c52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes some time to calculate FFT of all traces\n",
    "for ii, das_tr in enumerate(das_dws):\n",
    "    if ii==0:\n",
    "        tr_fft = fft.fft(das_tr)\n",
    "        f_len = int(tr_fft.size/2)\n",
    "        NqF = new_sampling_rate/2.0  #the Nyquist frequency\n",
    "        frequency = np.linspace(0, NqF, num=f_len)\n",
    "        tr_fft = abs(tr_fft[:f_len]) \n",
    "    else:\n",
    "        tr_fft=np.vstack((tr_fft, abs(fft.fft(das_tr)[:f_len])))\n",
    "        \n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "im = ax.imshow(tr_fft, aspect='auto', vmin=0, vmax=5e3,\n",
    "          extent=[0, frequency[-1], min(chan), max(chan)])\n",
    "ax.set_xlabel('Frequency (Hz)')\n",
    "ax.set_ylabel('Channel')\n",
    "#ax.set_xscale('log')\n",
    "ax.set_xlim([0, frequency[-1]])\n",
    "plt.colorbar(im, ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4fc4b2",
   "metadata": {},
   "source": [
    "## Part 2. Ocean Bottom DAS and f-k plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1253003a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Each file is 5-min long. \n",
    "# Here we read two files for Ch. 100-700 only and concatenate. \n",
    "folder = '/nfs/turbo/lsa-zspica/DASworkshop/' # change iy to your own folder with all files\n",
    "#data1=h5py.File(folder+'0000002830_2019-11-18_06.27.08.86990.hdf5','r')['DAS'][:,100:700]\n",
    "#data2=h5py.File(folder+'0000002832_2019-11-18_06.32.08.86990.hdf5','r')['DAS'][:,100:700]\n",
    "#data=np.concatenate((data1,data2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8d6a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Save data in a new file\n",
    "#with h5py.File(folder+'raw_10min_ch100-700_500hz.hdf5', 'w') as hdf:\n",
    "#    hdf.create_dataset('DAS',data=data)\n",
    "#    hdf.create_dataset('starttime',data='2019-11-18_06.27.08.86990')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e10582",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = h5py.File('raw_10min_ch100-700_500hz.hdf5', 'r')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a84339",
   "metadata": {},
   "source": [
    "### Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ebe2858",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(data):\n",
    "    \"\"\"\n",
    "    Convert raw data to strain rate\n",
    "    \n",
    "    The raw data is phase shift, scaled from -32768 to 32768, corresponding -pi to pi. \n",
    "    Phase shift needs to be converted to pi-scale and cumsum-ed to get phase data. \n",
    "    Phase data are then transformed into strain measurements by multiple a linear scaler,\n",
    "    which is determined by laser wavelenght, fiber refractive index, gauge length and optical-elastic coefficient.\n",
    "    Strain rate are also be calculated by differentiation.\n",
    "    \"\"\"\n",
    "    phase=np.cumsum(data*np.pi/32768,dtype='float')\n",
    "    strain=phase*1550*10**-9/(4*np.pi*1.47*0.78*40)\n",
    "    \n",
    "    strain_rate=[0]\n",
    "    for i in range(1,len(strain)):\n",
    "        strain_rate.append((strain[i]-strain[i-1])*500)\n",
    "    \n",
    "    return strain_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd9c472",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Read data (raw, 500hz)\n",
    "phase_500hz=h5py.File(folder+'raw_10min_ch100-700_500hz.hdf5','r')['DAS'][:,:]\n",
    "\n",
    "### Convert from raw to SR (500hz)\n",
    "sr_500hz=np.empty((phase_500hz.shape[0],phase_500hz.shape[1]))\n",
    "\n",
    "for i in range(phase_500hz.shape[1]):\n",
    "    sr_500hz[:,i]=convert(phase_500hz[:,i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2489ee0d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(sr_500hz,aspect='auto',cmap='viridis', vmin=-0.1*10**-6,vmax=0.1*10**-6)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0cc513f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Save SR data\n",
    "with h5py.File(folder+'sr_10min_ch100-700_500hz.hdf5', 'w') as hdf:\n",
    "    hdf.create_dataset('sr',data=sr_500hz)\n",
    "    hdf.create_dataset('starttime',data='2019-11-18_06.27.08.86990')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d88cbc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def taper(data, taper_dur, fs ):\n",
    "    \n",
    "    ### Hann taper with a width of 0.5*taper_dur\n",
    "    \n",
    "    hann_func = signal.hann(int(int(taper_dur*2)*fs)+1) \n",
    "    half_len = round(len(hann_func)/2-.001)\n",
    "    data[:half_len] = data[:half_len]*hann_func[:half_len]\n",
    "    data[-half_len:] = data[-half_len:]*hann_func[-half_len:]\n",
    "    return data\n",
    "\n",
    "def decimate(stream_data,factor: list,taper_dur,fs):\n",
    "    \"\"\"\n",
    "    decimate and tape the data\n",
    "    \n",
    "    Note that the input factor should be a list, containing a series of decimation factor.\n",
    "    If decimation factor is larger than 10, it should be done in two or more steps.\n",
    "    Eg. Instead of factor=[10], we do factor=[2,5]\n",
    "    \"\"\" \n",
    "    out_data=stream_data[:,0]\n",
    "    out_data=taper(out_data,taper_dur,fs)\n",
    "    temp_fs=fs\n",
    "    \n",
    "    for f in factor:\n",
    "        temp_fs=int(temp_fs/f)\n",
    "        out_data=signal.decimate(out_data,f,ftype='iir', zero_phase=True,axis=0)\n",
    "        out_data=taper(out_data,taper_dur,temp_fs)\n",
    "    \n",
    "    for i in range(1,stream_data.shape[-1]):\n",
    "        \n",
    "        trace_data=stream_data[:,i]\n",
    "        trace_data=taper(trace_data,taper_dur,fs)\n",
    "        temp_fs=fs\n",
    "        \n",
    "        for f in factor:\n",
    "            temp_fs=int(temp_fs/f)\n",
    "            trace_data=signal.decimate(trace_data,f,ftype='iir', zero_phase=True,axis=0)\n",
    "            trace_data=taper(trace_data,taper_dur,temp_fs)\n",
    "            \n",
    "        out_data=np.vstack((out_data,trace_data))\n",
    "        \n",
    "    return out_data.T\n",
    "\n",
    "def butter_bandpass_filter(data, lowcut, highcut, fs, order=4):\n",
    "    \n",
    "    ### forth order butterworth bandpass filter\n",
    "    \n",
    "    nyq = 0.5 * fs\n",
    "    low = lowcut / nyq\n",
    "    high = highcut / nyq\n",
    "    b, a = signal.butter(order, [low, high], btype='band')\n",
    "    y = signal.filtfilt(b, a, data)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc3308b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Decimate SR data from 500hz to 25hz\n",
    "sr_20hz=decimate(sr_500hz,[5,5],4,500)\n",
    "\n",
    "plt.imshow(sr_20hz,aspect='auto',cmap='viridis',vmin=-0.1*10**-6,vmax=0.1*10**-6)\n",
    "plt.colorbar()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8cd8b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Save data\n",
    "with h5py.File(folder+'sr_10min_ch100-700_20hz.hdf5', 'w') as hdf:\n",
    "    hdf.create_dataset('sr',data=sr_20hz)\n",
    "    hdf.create_dataset('starttime',data='2019-11-18_06.27.08.86990')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f46ac5",
   "metadata": {},
   "source": [
    "### f-k plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a9cfd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### FK plot visualizes the spectrum in both spatial and temporal domain.\n",
    "### Here we do a 2D fourier transform and covnert fourier amplitudes into log scale. \n",
    "\n",
    "spec=np.fft.fftshift(np.fft.fft2(sr_20hz[:,200:]))\n",
    "psd=10*np.log10(spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da623bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create meshgrid for plotting. \n",
    "### Here the SR data is 20 Hz, so the temporal resolution is 0.05s. Spatial resolution (channel spacing) is 5m.\n",
    "\n",
    "xs1=np.fft.fftfreq(12000,0.05)[0:500]\n",
    "xs2=np.fft.fftfreq(12000,0.05)[-500:]\n",
    "xs=np.concatenate((xs2,xs1))\n",
    "\n",
    "ys=np.fft.fftfreq(400,5)[0:200]\n",
    "\n",
    "X,Y=np.meshgrid(xs,ys)\n",
    "\n",
    "### Create a theoritical water wave dispersion relation for reference\n",
    "\n",
    "xp=np.arange(0,0.6,0.001)\n",
    "xn=-1*xp\n",
    "\n",
    "xl=(9.8*ys*2*np.pi*np.tanh(ys*100*2*np.pi))**0.5/(2*np.pi)\n",
    "xln=-(9.8*ys*2*np.pi*np.tanh(ys*100*2*np.pi))**0.5/(2*np.pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc346973",
   "metadata": {},
   "outputs": [],
   "source": [
    "formula=r'\\omega^2= g\\:k\\:tanh(k\\:H)'\n",
    "\n",
    "cmap = plt.get_cmap('YlGnBu')\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.xlim((-0.6,0.6))\n",
    "plt.ylim((0,0.04))\n",
    "plt.pcolormesh(X,Y,np.flip(psd.real[5500:6500,0:200].T,axis=0),cmap=cmap,zorder=0,vmin=-40,vmax=-15)\n",
    "\n",
    "cbar=plt.colorbar(orientation=\"horizontal\",fraction=0.046,pad=0.16)\n",
    "cbar.set_label('Amplitude (db [$10 log10($s^{-1}$)\\u00b2/Hz$])',fontsize=10)\n",
    "\n",
    "plt.xlabel('Frequency (1/s)',fontsize=12)\n",
    "plt.ylabel('Wavenumber (1/m))',fontsize=12)\n",
    "plt.plot(xl,ys,'black',linestyle='-.',label='$%s$' %formula)\n",
    "plt.plot(xln,ys,'black',linestyle='-.')\n",
    "plt.plot(xp,xp/30,c='r')\n",
    "plt.plot(xn,-xn/30,c='r')\n",
    "plt.axvline(x=0,c='b',alpha=0.4)\n",
    "\n",
    "plt.text(0.3,0.006,'30 m/s',fontsize=12)\n",
    "plt.text(-0.4,0.006,'30 m/s',fontsize=12)\n",
    "plt.text(0.2,0.0085,'Seaward',size=15,c='r',rotation=30)\n",
    "plt.text(-0.35,0.0065,'Landward',size=15,c='r',rotation=330)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3864c166",
   "metadata": {},
   "source": [
    "**References:**\n",
    "- [IntroToDASData](https://github.com/DAS-RCN/IntroToDASData)\n",
    "- [roses2021 DAS with Dr. Eileen Martin](https://connect.agu.org/seismology/roses/roses2021materials)\n",
    "- [NoisePy](https://noise-python.readthedocs.io/en/latest/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f700bf1f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "205a6b395895f6e90f0399dcdf562fc06c2234525b5e2878bc497896867e4da7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
